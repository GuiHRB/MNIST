# üß† An√°lise de Robustez de Redes Neurais com Dropout (MNIST)

## üìã Breve Descri√ß√£o do Projeto

Este projeto consiste em uma investiga√ß√£o sobre a **robustez e a efic√°cia do mecanismo de Dropout** como t√©cnica de regulariza√ß√£o em Redes Neurais Artificiais (RNAs) contra o **overfitting** e a **presen√ßa de ru√≠do** nos dados.

O estudo utiliza o cl√°ssico dataset de d√≠gitos manuscritos **MNIST**. V√°rios modelos de RNAs sequenciais foram treinados, cada um com uma **taxa de Dropout diferente** (variando de 0.1 a 0.5), para determinar qual taxa oferece o melhor equil√≠brio entre:

1.  **Acur√°cia M√°xima** (em dados limpos).
2.  **Estabilidade de Treinamento** (resist√™ncia ao *overfitting*).
3.  **Robustez** (capacidade de manter a alta acur√°cia em dados modificados com **ru√≠do Gaussiano**).

Os resultados mostram que o **Dropout de 0.2** oferece o melhor ponto de equil√≠brio, mantendo uma alta acur√°cia de $97.6\%$ e sofrendo a menor queda de performance em cen√°rios ruidosos.

---

## üöÄ Como Executar o Projeto

O projeto est√° configurado para ser executado em um ambiente de notebook (Jupyter Notebook, Google Colab ou VS Code).

### Pr√©-requisitos

Certifique-se de que as seguintes bibliotecas Python estejam instaladas:

TensorFlow / Keras
NumPy	
Matplotlib
Scikit-learn
